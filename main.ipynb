{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ff94aa0622800b",
   "metadata": {},
   "source": [
    "Flow for a machine learning project\n",
    "\n",
    "1. Load configuration\n",
    "2. Initialize data processor\n",
    "3. Load and preprocess housing data\n",
    "4. For each edge connectivity method:\n",
    "   a. Build graph with specific connectivity\n",
    "   b. For each model type (Simple/Multi-layer):\n",
    "      - Initialize model\n",
    "      - Train model\n",
    "      - Evaluate on validation set\n",
    "      - Save results\n",
    "5. Compare all results\n",
    "6. Get test result and Generate final report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eddd025",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a35ef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cef2d66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN Real Estate Price Prediction Setup\n"
     ]
    }
   ],
   "source": [
    "# Imports and Initial Setup\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Force reload modules\n",
    "import importlib\n",
    "import sys\n",
    "modules_to_reload = ['config', 'data_processor', 'models', 'trainer', 'graph_builder']\n",
    "for module in modules_to_reload:\n",
    "    if module in sys.modules:\n",
    "        del sys.modules[module]\n",
    "\n",
    "from config import Config\n",
    "from data_processor import DataProcessor\n",
    "from models import SimpleGCN, SimpleGAT,MultiLayerGCN\n",
    "from trainer import Trainer\n",
    "\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"GNN Real Estate Price Prediction Setup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0774a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_processor\n",
    "import importlib\n",
    "importlib.reload(data_processor)\n",
    "from data_processor import DataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5ec905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import data_processor, models, trainer, config, graph_builder\n",
    "\n",
    "importlib.reload(data_processor)\n",
    "importlib.reload(models)\n",
    "importlib.reload(trainer)\n",
    "importlib.reload(config)\n",
    "importlib.reload(graph_builder)\n",
    "\n",
    "from data_processor import DataProcessor\n",
    "from models import SimpleGCN, SimpleGAT, MultiLayerGCN\n",
    "from trainer import Trainer\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e828057",
   "metadata": {},
   "source": [
    "Feature Engineering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a7bfd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering functions loaded\n"
     ]
    }
   ],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"Add engineered features that might improve prediction\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    print(\"Engineering new features\")\n",
    "    \n",
    "    # Price per sqft \n",
    "    df['price_per_sqft'] = df['price'] / df['sqft_living']\n",
    "    \n",
    "    # Total sqft\n",
    "    df['total_sqft'] = df['sqft_above'] + df['sqft_basement']\n",
    "    \n",
    "    # Bathroom to bedroom ratio\n",
    "    df['bath_bed_ratio'] = df['bathrooms'] / np.maximum(df['bedrooms'], 1)\n",
    "    \n",
    "    # Age of house assuming current year is 2015 based on data\n",
    "    current_year = 2015\n",
    "    df['house_age'] = current_year - df['yr_built']\n",
    "    \n",
    "    # Years since renovation 0 if never renovated\n",
    "    df['years_since_reno'] = np.where(df['yr_renovated'] == 0, \n",
    "                                     df['house_age'], \n",
    "                                     current_year - df['yr_renovated'])\n",
    "    \n",
    "    # Binary features\n",
    "    df['has_basement'] = (df['sqft_basement'] > 0).astype(int)\n",
    "    df['has_been_renovated'] = (df['yr_renovated'] > 0).astype(int)\n",
    "    df['is_luxury'] = ((df['grade'] >= 10) | (df['waterfront'] == 1) | (df['view'] >= 3)).astype(int)\n",
    "    \n",
    "    # Living space efficiency living sqft / lot sqft\n",
    "    df['space_efficiency'] = df['sqft_living'] / np.maximum(df['sqft_lot'], 1)\n",
    "    \n",
    "    print(f\"Added 9 engineered features\")\n",
    "    return df\n",
    "\n",
    "def create_neighborhood_features(df):\n",
    "    \"\"\"Create neighborhood-based features using geographic proximity\"\"\"\n",
    "    print(\"Creating neighborhood features...\")\n",
    "    \n",
    "    # Create a simple grid-based neighborhood (0.01 degree bins)\n",
    "    lat_bins = pd.cut(df['lat'], bins=50, labels=False)\n",
    "    long_bins = pd.cut(df['long'], bins=50, labels=False)\n",
    "    df['neighborhood_id'] = lat_bins * 50 + long_bins\n",
    "    \n",
    "    # Calculate neighborhood statistics\n",
    "    neighborhood_stats = df.groupby('neighborhood_id')['price'].agg(['mean', 'median', 'std', 'count']).reset_index()\n",
    "    neighborhood_stats.columns = ['neighborhood_id', 'neighborhood_price_mean', 'neighborhood_price_median', 'neighborhood_price_std', 'neighborhood_count']\n",
    "    \n",
    "    # Merge back with original data\n",
    "    df = df.merge(neighborhood_stats, on='neighborhood_id', how='left')\n",
    "    \n",
    "    # Fill NaN values\n",
    "    df['neighborhood_price_std'] = df['neighborhood_price_std'].fillna(df['price'].std())\n",
    "    \n",
    "    print(f\"Created neighborhood features for {df['neighborhood_id'].nunique()} neighborhoods\")\n",
    "    return df\n",
    "\n",
    "print(\"Feature engineering functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ed74fa",
   "metadata": {},
   "source": [
    "Configuration Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "576997a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration Setup Complete\n",
      "   Features to use: 19\n",
      "   Epochs: 50\n",
      "   Learning rate: 0.001\n",
      "\n",
      "Hardware Check:\n",
      "   CUDA available: True\n",
      "   GPU: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "   GPU memory: 4.3 GB\n",
      "   CPU threads: 8\n"
     ]
    }
   ],
   "source": [
    "class ImprovedConfig(Config):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Add engineered features to embedding features\n",
    "        self.embedding_features = [\n",
    "            \"bedrooms\", \"bathrooms\", \"sqft_living\", \"floors\",\n",
    "            \"grade\", \"condition\", \"sqft_above\", \"sqft_basement\",\n",
    "            # New engineered features\n",
    "            \"total_sqft\", \"bath_bed_ratio\", \"house_age\", \"years_since_reno\",\n",
    "            \"has_basement\", \"has_been_renovated\", \"is_luxury\", \"space_efficiency\",\n",
    "            \"neighborhood_price_mean\", \"neighborhood_price_median\", \"neighborhood_price_std\"\n",
    "        ]\n",
    "        # Training parameters\n",
    "        self.default_epochs = 50  # Adjust as needed\n",
    "        self.default_learning_rate = 0.001\n",
    "\n",
    "# Initialize configuration\n",
    "cfg = ImprovedConfig()\n",
    "processor = DataProcessor(cfg)\n",
    "\n",
    "print(\"Configuration Setup Complete\")\n",
    "print(f\"   Features to use: {len(cfg.embedding_features)}\")\n",
    "print(f\"   Epochs: {cfg.default_epochs}\")\n",
    "print(f\"   Learning rate: {cfg.default_learning_rate}\")\n",
    "\n",
    "# Hardware check\n",
    "print(f\"\\nHardware Check:\")\n",
    "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"   GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(f\"   Using CPU\")\n",
    "print(f\"   CPU threads: {torch.get_num_threads()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc1c732",
   "metadata": {},
   "source": [
    "Data Loading and Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0fef1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and Processing Data\n",
      "Loading raw data from: C:/Users/Yuval Rainis/Desktop/School/2025 B/Dlab/Project/kc_final.csv\n",
      "Loaded 21613 rows and 22 columns\n",
      "Data loaded in 0.03s\n",
      "   Shape: (21613, 22)\n",
      "   Columns: 22\n",
      "\n",
      "Basic Statistics:\n",
      "   Price range: $75,000 - $7,700,000\n",
      "   Mean price: $540,088\n",
      "   Median price: $450,000\n",
      "\n",
      "Applying Feature Engineering...\n",
      "Engineering new features\n",
      "Added 9 engineered features\n",
      "Creating neighborhood features...\n",
      "Created neighborhood features for 880 neighborhoods\n",
      "Feature engineering completed in 0.01s\n",
      "   Enhanced shape: (21613, 36)\n",
      "\n",
      "Sample of new features:\n",
      "   price_per_sqft  house_age  bath_bed_ratio  is_luxury  \\\n",
      "0             188         60               0          0   \n",
      "1             209         64               1          0   \n",
      "2             234         82               0          0   \n",
      "3             308         50               1          0   \n",
      "4             304         28               1          0   \n",
      "\n",
      "   neighborhood_price_mean  \n",
      "0                  292,615  \n",
      "1                  410,848  \n",
      "2                  420,692  \n",
      "3                  518,620  \n",
      "4                  539,100  \n",
      "\n",
      "Data loading timing:\n",
      "   Raw loading: 0.03s\n",
      "   Feature engineering: 0.01s\n",
      "   Total: 0.05s\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading and Processing Data\")\n",
    "\n",
    "# Load raw data\n",
    "start_time = time.time()\n",
    "df = processor.load_raw()\n",
    "load_time = time.time() - start_time\n",
    "\n",
    "print(f\"Data loaded in {load_time:.2f}s\")\n",
    "print(f\"   Shape: {df.shape}\")\n",
    "print(f\"   Columns: {len(df.columns)}\")\n",
    "\n",
    "# Show basic statistics\n",
    "print(f\"\\nBasic Statistics:\")\n",
    "print(f\"   Price range: ${df['price'].min():,.0f} - ${df['price'].max():,.0f}\")\n",
    "print(f\"   Mean price: ${df['price'].mean():,.0f}\")\n",
    "print(f\"   Median price: ${df['price'].median():,.0f}\")\n",
    "\n",
    "# Feature engineering\n",
    "feature_start = time.time()\n",
    "print(f\"\\nApplying Feature Engineering...\")\n",
    "df = engineer_features(df)\n",
    "df = create_neighborhood_features(df)\n",
    "feature_time = time.time() - feature_start\n",
    "\n",
    "print(f\"Feature engineering completed in {feature_time:.2f}s\")\n",
    "print(f\"   Enhanced shape: {df.shape}\")\n",
    "\n",
    "# Show sample of new features\n",
    "new_features = ['price_per_sqft', 'house_age', 'bath_bed_ratio', 'is_luxury', 'neighborhood_price_mean']\n",
    "print(f\"\\nSample of new features:\")\n",
    "print(df[new_features].head())\n",
    "\n",
    "print(f\"\\nData loading timing:\")\n",
    "print(f\"   Raw loading: {load_time:.2f}s\")\n",
    "print(f\"   Feature engineering: {feature_time:.2f}s\")\n",
    "print(f\"   Total: {load_time + feature_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0f286a",
   "metadata": {},
   "source": [
    "Data Preprocessing and Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e694931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Data Preprocessing...\n",
      "Saved spatial features to: data/spatial_features.csv\n",
      "Spatial features shape: (21613, 2)\n",
      "Preprocessing data...\n",
      "Removed 0 rows with NaN values\n",
      "Features shape: (21613, 19)\n",
      "Labels shape: (21613, 1)\n",
      "Scaled features shape: (21613, 19)\n",
      "Scaled labels shape: (21613,)\n",
      "Saved feature statistics to: data/feature_statistics.csv\n",
      "✅ Preprocessing completed in 0.06s\n",
      "   Features shape: (21613, 19)\n",
      "   Labels shape: (21613,)\n",
      "\n",
      "📊 Creating Train/Val/Test Split...\n",
      "✅ Split created:\n",
      "   Train: 15,129 samples (70.0%)\n",
      "   Val:   3,241 samples (15.0%)\n",
      "   Test:  3,243 samples (15.0%)\n",
      "\n",
      "🔧 Building graphs per split (train / val / test)...\n",
      "🔄 Building separate graphs for Train / Val / Test\n",
      "  Building train graph with 15129 nodes...\n",
      "GraphBuilder initialized with concentric radii + similarity filtering\n",
      "  X shape: (15129, 19), geo shape: (15129, 2), y shape: (15129,)\n",
      "  Structural features shape: (15129, 5)\n",
      "  Quality features shape: (15129, 3)\n",
      "  Building validation graph with 3241 nodes...\n",
      "GraphBuilder initialized with concentric radii + similarity filtering\n",
      "  X shape: (3241, 19), geo shape: (3241, 2), y shape: (3241,)\n",
      "  Structural features shape: (3241, 5)\n",
      "  Quality features shape: (3241, 3)\n",
      "  Building test graph with 3243 nodes...\n",
      "GraphBuilder initialized with concentric radii + similarity filtering\n",
      "  X shape: (3243, 19), geo shape: (3243, 2), y shape: (3243,)\n",
      "  Structural features shape: (3243, 5)\n",
      "  Quality features shape: (3243, 3)\n",
      "✅ Split graphs created:\n",
      "   Train: 15129 nodes, 211402 edges\n",
      "   Val:   3241 nodes, 45353 edges\n",
      "   Test:  3243 nodes, 45385 edges\n",
      "✅ Graphs created in 14.56s\n",
      "   Train Nodes: 15,129, Edges: 211,402\n",
      "   Val Nodes:   3,241, Edges: 45,353\n",
      "   Test Nodes:  3,243, Edges: 45,385\n"
     ]
    }
   ],
   "source": [
    "print(\" Data Preprocessing...\")\n",
    "\n",
    "# Create spatial features and preprocess\n",
    "preprocess_start = time.time()\n",
    "processor.create_spatial_features(df)\n",
    "X, y = processor.preprocess(df)\n",
    "preprocess_time = time.time() - preprocess_start\n",
    "\n",
    "print(f\" Preprocessing completed in {preprocess_time:.2f}s\")\n",
    "print(f\"   Features shape: {X.shape}\")\n",
    "print(f\"   Labels shape: {y.shape}\")\n",
    "\n",
    "\n",
    "print(\"\\n Creating Train/Val/Test Split...\")\n",
    "\n",
    "# Create indices and split\n",
    "n_nodes = len(X)\n",
    "indices = np.arange(n_nodes)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_ratio, val_ratio, test_ratio = 0.7, 0.15, 0.15\n",
    "train_size = int(train_ratio * n_nodes)\n",
    "val_size = int(val_ratio * n_nodes)\n",
    "\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:train_size + val_size]\n",
    "test_indices = indices[train_size + val_size:]\n",
    "\n",
    "# Build boolean masks\n",
    "train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[train_indices] = True\n",
    "val_mask[val_indices] = True\n",
    "test_mask[test_indices] = True\n",
    "\n",
    "print(f\"Split created:\")\n",
    "print(f\"   Train: {train_mask.sum():,} samples ({train_mask.sum()/n_nodes*100:.1f}%)\")\n",
    "print(f\"   Val:   {val_mask.sum():,} samples ({val_mask.sum()/n_nodes*100:.1f}%)\")\n",
    "print(f\"   Test:  {test_mask.sum():,} samples ({test_mask.sum()/n_nodes*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n🔧 Building graphs per split (train / val / test)...\")\n",
    "graph_start = time.time()\n",
    "data_train, data_val, data_test = processor.create_split_graphs(X, y, train_mask, val_mask, test_mask)\n",
    "graph_time = time.time() - graph_start\n",
    "\n",
    "print(f\" Graphs created in {graph_time:.2f}s\")\n",
    "print(f\"   Train Nodes: {data_train.num_nodes:,}, Edges: {data_train.num_edges:,}\")\n",
    "print(f\"   Val Nodes:   {data_val.num_nodes:,}, Edges: {data_val.num_edges:,}\")\n",
    "print(f\"   Test Nodes:  {data_test.num_nodes:,}, Edges: {data_test.num_edges:,}\")\n",
    "\n",
    "# Wrap for trainer\n",
    "data_list_train = [data_train]\n",
    "data_list_val = [data_val]\n",
    "data_list_test = [data_test]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896741a6",
   "metadata": {},
   "source": [
    "Model Training and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e0ce8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Deep Models...\n",
      "========================================\n",
      "SimpleGCN upgraded: 56,097 parameters, 5 conv layers, hidden_dim=128\n",
      "SimpleGAT upgraded: 429,377 parameters, 4 heads, hidden_dim=128\n",
      "MultiLayerGCN upgraded: 118,481 parameters, 5 layers, dims=[256, 128, 64, 32, 16]\n",
      "🔧 Training settings: 100 epochs, LR=0.0005\n",
      "\n",
      "==================================================\n",
      "Training GCN Model\n",
      "==================================================\n",
      "   Parameters: 56,097\n",
      "Using device: cuda\n",
      "\n",
      "Starting full training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   3%|▎         | 3/100 [00:00<00:14,  6.85it/s, Train Loss=0.0341, Val Loss=0.0106, MAE=0.0905, RMSE=0.1028]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1: Train Loss = 0.0725, Val Loss = 0.0147, MAE = 0.1117, RMSE = 0.1213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  13%|█▎        | 13/100 [00:01<00:05, 15.38it/s, Train Loss=0.0092, Val Loss=0.0134, MAE=0.1094, RMSE=0.1157]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10: Train Loss = 0.0113, Val Loss = 0.0093, MAE = 0.0884, RMSE = 0.0964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  21%|██        | 21/100 [00:01<00:04, 16.63it/s, Train Loss=0.0056, Val Loss=0.0071, MAE=0.0765, RMSE=0.0840]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  20: Train Loss = 0.0063, Val Loss = 0.0098, MAE = 0.0929, RMSE = 0.0992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  31%|███       | 31/100 [00:02<00:04, 16.54it/s, Train Loss=0.0042, Val Loss=0.0033, MAE=0.0471, RMSE=0.0574]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  30: Train Loss = 0.0044, Val Loss = 0.0039, MAE = 0.0530, RMSE = 0.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  41%|████      | 41/100 [00:02<00:03, 16.20it/s, Train Loss=0.0035, Val Loss=0.0020, MAE=0.0334, RMSE=0.0445]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  40: Train Loss = 0.0036, Val Loss = 0.0022, MAE = 0.0358, RMSE = 0.0469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  53%|█████▎    | 53/100 [00:03<00:02, 16.94it/s, Train Loss=0.0031, Val Loss=0.0020, MAE=0.0340, RMSE=0.0447]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  50: Train Loss = 0.0033, Val Loss = 0.0020, MAE = 0.0338, RMSE = 0.0447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  61%|██████    | 61/100 [00:04<00:02, 17.09it/s, Train Loss=0.0029, Val Loss=0.0019, MAE=0.0334, RMSE=0.0439]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  60: Train Loss = 0.0029, Val Loss = 0.0020, MAE = 0.0337, RMSE = 0.0442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  71%|███████   | 71/100 [00:04<00:01, 16.53it/s, Train Loss=0.0026, Val Loss=0.0019, MAE=0.0329, RMSE=0.0434]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  70: Train Loss = 0.0027, Val Loss = 0.0019, MAE = 0.0332, RMSE = 0.0436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  83%|████████▎ | 83/100 [00:05<00:00, 17.33it/s, Train Loss=0.0025, Val Loss=0.0018, MAE=0.0321, RMSE=0.0427]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  80: Train Loss = 0.0025, Val Loss = 0.0018, MAE = 0.0322, RMSE = 0.0427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  91%|█████████ | 91/100 [00:05<00:00, 16.65it/s, Train Loss=0.0024, Val Loss=0.0018, MAE=0.0319, RMSE=0.0423]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  90: Train Loss = 0.0024, Val Loss = 0.0018, MAE = 0.0319, RMSE = 0.0423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 100/100 [00:06<00:00, 15.88it/s, Train Loss=0.0023, Val Loss=0.0017, MAE=0.0310, RMSE=0.0416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Train Loss = 0.0023, Val Loss = 0.0017, MAE = 0.0310, RMSE = 0.0416\n",
      "\n",
      "✅ Training completed. Best validation loss: 0.0017\n",
      "GCN training completed in 6.30s\n",
      "\n",
      "GCN Results:\n",
      "   MAE:    $224,240\n",
      "   RMSE:   $297,068\n",
      "   MAPE:   55.77%\n",
      "   MEDAPE: 41.57%\n",
      "   Training time: 6.30s\n",
      "   Parameters: 56,097\n",
      "   GPU memory: 0.44 GB\n",
      "\n",
      "==================================================\n",
      "Training GAT Model\n",
      "==================================================\n",
      "   Parameters: 429,377\n",
      "Using device: cuda\n",
      "\n",
      "Starting full training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 1/100 [00:00<00:26,  3.72it/s, Train Loss=0.1185, Val Loss=0.0029, MAE=0.0372, RMSE=0.0540]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1: Train Loss = 0.1185, Val Loss = 0.0029, MAE = 0.0372, RMSE = 0.0540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  10%|█         | 10/100 [00:02<00:19,  4.68it/s, Train Loss=0.0218, Val Loss=0.0444, MAE=0.2067, RMSE=0.2107]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10: Train Loss = 0.0218, Val Loss = 0.0444, MAE = 0.2067, RMSE = 0.2107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  20%|██        | 20/100 [00:04<00:17,  4.66it/s, Train Loss=0.0110, Val Loss=0.0041, MAE=0.0569, RMSE=0.0644]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  20: Train Loss = 0.0110, Val Loss = 0.0041, MAE = 0.0569, RMSE = 0.0644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  30%|███       | 30/100 [00:06<00:14,  4.69it/s, Train Loss=0.0071, Val Loss=0.0031, MAE=0.0480, RMSE=0.0553]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  30: Train Loss = 0.0071, Val Loss = 0.0031, MAE = 0.0480, RMSE = 0.0553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  40%|████      | 40/100 [00:08<00:12,  4.66it/s, Train Loss=0.0056, Val Loss=0.0018, MAE=0.0320, RMSE=0.0420]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  40: Train Loss = 0.0056, Val Loss = 0.0018, MAE = 0.0320, RMSE = 0.0420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  50%|█████     | 50/100 [00:10<00:10,  4.69it/s, Train Loss=0.0046, Val Loss=0.0019, MAE=0.0350, RMSE=0.0438]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  50: Train Loss = 0.0046, Val Loss = 0.0019, MAE = 0.0350, RMSE = 0.0438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  60%|██████    | 60/100 [00:12<00:08,  4.66it/s, Train Loss=0.0041, Val Loss=0.0016, MAE=0.0297, RMSE=0.0399]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  60: Train Loss = 0.0041, Val Loss = 0.0016, MAE = 0.0297, RMSE = 0.0399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  70%|███████   | 70/100 [00:15<00:06,  4.61it/s, Train Loss=0.0037, Val Loss=0.0016, MAE=0.0300, RMSE=0.0399]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  70: Train Loss = 0.0037, Val Loss = 0.0016, MAE = 0.0300, RMSE = 0.0399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  80%|████████  | 80/100 [00:17<00:04,  4.63it/s, Train Loss=0.0034, Val Loss=0.0015, MAE=0.0279, RMSE=0.0384]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  80: Train Loss = 0.0034, Val Loss = 0.0015, MAE = 0.0279, RMSE = 0.0384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  90%|█████████ | 90/100 [00:19<00:02,  4.67it/s, Train Loss=0.0032, Val Loss=0.0014, MAE=0.0272, RMSE=0.0379]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  90: Train Loss = 0.0032, Val Loss = 0.0014, MAE = 0.0272, RMSE = 0.0379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 100/100 [00:21<00:00,  4.65it/s, Train Loss=0.0029, Val Loss=0.0014, MAE=0.0258, RMSE=0.0369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Train Loss = 0.0029, Val Loss = 0.0014, MAE = 0.0258, RMSE = 0.0369\n",
      "\n",
      "✅ Training completed. Best validation loss: 0.0014\n",
      "GAT training completed in 21.50s\n",
      "\n",
      "GAT Results:\n",
      "   MAE:    $187,220\n",
      "   RMSE:   $258,362\n",
      "   MAPE:   43.50%\n",
      "   MEDAPE: 34.45%\n",
      "   Training time: 21.50s\n",
      "   Parameters: 429,377\n",
      "   GPU memory: 3.69 GB\n",
      "\n",
      "==================================================\n",
      "Training MultiGCN Model\n",
      "==================================================\n",
      "   Parameters: 118,481\n",
      "Using device: cuda\n",
      "\n",
      "Starting full training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s, Train Loss=0.0184, Val Loss=0.0073, MAE=0.0763, RMSE=0.0856]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1: Train Loss = 0.0184, Val Loss = 0.0073, MAE = 0.0763, RMSE = 0.0856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  12%|█▏        | 12/100 [00:00<00:06, 13.28it/s, Train Loss=0.0096, Val Loss=0.0064, MAE=0.0730, RMSE=0.0800]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10: Train Loss = 0.0100, Val Loss = 0.0075, MAE = 0.0799, RMSE = 0.0864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  22%|██▏       | 22/100 [00:01<00:05, 13.39it/s, Train Loss=0.0063, Val Loss=0.0025, MAE=0.0380, RMSE=0.0503]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  20: Train Loss = 0.0068, Val Loss = 0.0030, MAE = 0.0441, RMSE = 0.0549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  32%|███▏      | 32/100 [00:02<00:05, 13.11it/s, Train Loss=0.0047, Val Loss=0.0018, MAE=0.0249, RMSE=0.0426]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  30: Train Loss = 0.0048, Val Loss = 0.0019, MAE = 0.0259, RMSE = 0.0434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  42%|████▏     | 42/100 [00:03<00:04, 13.12it/s, Train Loss=0.0039, Val Loss=0.0015, MAE=0.0229, RMSE=0.0388]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  40: Train Loss = 0.0040, Val Loss = 0.0016, MAE = 0.0232, RMSE = 0.0395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  52%|█████▏    | 52/100 [00:03<00:03, 12.98it/s, Train Loss=0.0033, Val Loss=0.0013, MAE=0.0227, RMSE=0.0365]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  50: Train Loss = 0.0034, Val Loss = 0.0014, MAE = 0.0225, RMSE = 0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  62%|██████▏   | 62/100 [00:04<00:02, 13.09it/s, Train Loss=0.0030, Val Loss=0.0013, MAE=0.0228, RMSE=0.0360]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  60: Train Loss = 0.0030, Val Loss = 0.0013, MAE = 0.0228, RMSE = 0.0360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  72%|███████▏  | 72/100 [00:05<00:02, 13.25it/s, Train Loss=0.0027, Val Loss=0.0013, MAE=0.0226, RMSE=0.0361]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  70: Train Loss = 0.0027, Val Loss = 0.0013, MAE = 0.0227, RMSE = 0.0361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  82%|████████▏ | 82/100 [00:06<00:01, 13.39it/s, Train Loss=0.0025, Val Loss=0.0013, MAE=0.0223, RMSE=0.0360]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  80: Train Loss = 0.0026, Val Loss = 0.0013, MAE = 0.0222, RMSE = 0.0359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  92%|█████████▏| 92/100 [00:07<00:00, 13.17it/s, Train Loss=0.0024, Val Loss=0.0013, MAE=0.0223, RMSE=0.0360]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  90: Train Loss = 0.0024, Val Loss = 0.0013, MAE = 0.0224, RMSE = 0.0360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 100/100 [00:07<00:00, 13.08it/s, Train Loss=0.0023, Val Loss=0.0013, MAE=0.0221, RMSE=0.0360]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Train Loss = 0.0023, Val Loss = 0.0013, MAE = 0.0221, RMSE = 0.0360\n",
      "\n",
      "✅ Training completed. Best validation loss: 0.0013\n",
      "MultiGCN training completed in 7.65s\n",
      "\n",
      "MultiGCN Results:\n",
      "   MAE:    $165,532\n",
      "   RMSE:   $250,254\n",
      "   MAPE:   36.32%\n",
      "   MEDAPE: 26.52%\n",
      "   Training time: 7.65s\n",
      "   Parameters: 118,481\n",
      "   GPU memory: 0.80 GB\n",
      "\n",
      "🏁 Deep model training completed!\n",
      "🏆 Best model: MultiGCN with 36.32% MAPE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Deep Models...\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "models_to_try = {\n",
    "    'GCN': SimpleGCN(input_dim=X.shape[1], hidden_dim=128, dropout=0.4),\n",
    "    'GAT': SimpleGAT(input_dim=X.shape[1], hidden_dim=128, heads=4, dropout=0.4), \n",
    "    'MultiGCN': MultiLayerGCN(input_dim=X.shape[1], hidden_dims=[256, 128, 64, 32, 16], dropout=0.4)\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_mape = float('inf')\n",
    "results = {}\n",
    "\n",
    "advanced_epochs = 100\n",
    "advanced_lr = 0.0005\n",
    "\n",
    "print(f\"Training settings: {advanced_epochs} epochs, LR={advanced_lr}\")\n",
    "\n",
    "for model_name, model in models_to_try.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {model_name} Model\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    param_count = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"   Parameters: {param_count:,}\")\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=advanced_lr, weight_decay=1e-4)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    original_epochs = cfg.default_epochs\n",
    "    original_lr = cfg.default_learning_rate\n",
    "    cfg.default_epochs = advanced_epochs\n",
    "    cfg.default_learning_rate = advanced_lr\n",
    "\n",
    "    trainer = Trainer(model, optimizer, criterion, cfg)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    print(f\"\\nStarting full training...\")\n",
    "    full_training_start = time.time()\n",
    "    trainer.fit(data_list_train, data_list_val)\n",
    "    full_training_time = time.time() - full_training_start\n",
    "\n",
    "    print(f\"{model_name} training completed in {full_training_time:.2f}s\")\n",
    "\n",
    "    test_start = time.time()\n",
    "    test_loss, test_mae, test_rmse = trainer.validate(data_list_test)\n",
    "    test_time = time.time() - test_start\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data_test_device = data_list_test[0].to(trainer.device)\n",
    "        predictions = model(data_test_device).cpu().numpy()\n",
    "        targets = data_test_device.y.cpu().numpy()\n",
    "\n",
    "    test_pred_orig = processor.label_scaler.inverse_transform(predictions.reshape(-1, 1)).flatten()\n",
    "    test_actual_orig = processor.label_scaler.inverse_transform(targets.reshape(-1, 1)).flatten()\n",
    "\n",
    "    test_mae_orig = np.mean(np.abs(test_pred_orig - test_actual_orig))\n",
    "    test_rmse_orig = np.sqrt(np.mean((test_pred_orig - test_actual_orig) ** 2))\n",
    "    relative_errors = np.abs((test_actual_orig - test_pred_orig) / np.maximum(test_actual_orig, 1))\n",
    "    test_mape = np.mean(relative_errors) * 100\n",
    "    test_medape = np.median(relative_errors) * 100 \n",
    "\n",
    "    results[model_name] = {\n",
    "        'mae': test_mae_orig,\n",
    "        'rmse': test_rmse_orig,\n",
    "        'mape': test_mape,\n",
    "        'medape': test_medape,\n",
    "        'training_time': full_training_time,\n",
    "        'test_time': test_time,\n",
    "        'predictions': test_pred_orig,\n",
    "        'actual': test_actual_orig,\n",
    "        'param_count': param_count\n",
    "    }\n",
    "\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"   MAE:    ${test_mae_orig:,.0f}\")\n",
    "    print(f\"   RMSE:   ${test_rmse_orig:,.0f}\")\n",
    "    print(f\"   MAPE:   {test_mape:.2f}%\")\n",
    "    print(f\"   MEDAPE: {test_medape:.2f}%\")  \n",
    "    print(f\"   Training time: {full_training_time:.2f}s\")\n",
    "    print(f\"   Parameters: {param_count:,}\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        memory_used = torch.cuda.max_memory_allocated() / 1e9\n",
    "        print(f\"   GPU memory: {memory_used:.2f} GB\")\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    if test_mape < best_mape:\n",
    "        best_mape = test_mape\n",
    "        best_model = model_name\n",
    "\n",
    "    cfg.default_epochs = original_epochs\n",
    "    cfg.default_learning_rate = original_lr\n",
    "\n",
    "print(f\"\\nDeep model training completed!\")\n",
    "print(f\"Best model: {best_model} with {best_mape:.2f}% MAPE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mygpuenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
